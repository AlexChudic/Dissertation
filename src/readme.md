# Readme

The project aims to assess the refactoring skills of the Large Language Models (LLMs). We built a pipeline which samples GitHub repositories for evaluation, uses the RefactoringMiner to mine the refactorings performed by the developers, prompts gpt-3.5-turbo-0125 model using the OPENAI's API and evaluates the changes in code quality these refactorings produce using SonarQube. There is also a script that produces tables and figures used as evidence for our findings.

The folder structure is structured as follows:
* `src/` folder holds most of the Python scrips and Jupyter notebooks used by the pipeline
* `src/data-mining/mining/src/main/java/refactoring_mining/` stores the Java files used by the pipeline
* `data/` folder stores the tables and figures generated by the `src/evaluation.py` script and the `data/evaluate_repositories.json` JSON which holds the repository data for the evaluation
* `tmp/` folder is used to clone the repositories which are being mined and analysed

## Build instructions

To successfully build the project, please follow the setup instructions in the [readMe](https://github.com/AlexChudic/FinalProject/blob/main/README.md) of the project or the ones supplied below.

### Requirements

To run the project successfully, you will require the following software:

* Python 3.7
* Java 17 or newer
* Packages: listed in `requirements.txt`

To run the whole pipeline, you will also require:
* To retrieve a population of all GitHub repositories in the population, a GitHub API key is required - - needs to be added into the `src/.env` file
* To be able to prompt OPENAI API, an account and an API key are required - needs to be added into the `src/.env` file
* To analyse the source code using SonarQube, further setup is required - described [here](https://github.com/AlexChudic/FinalProject/edit/main/src/readme.md#sonarqube-and-sonarscanner-setup)
* Tested on Mac

### Sonarqube and SonarScanner setup
1. [Download](https://docs.sonarsource.com/sonarqube/latest/try-out-sonarqube/#installing-a-local-instance-of-sonarqube) and install a local instance of Sonarqube
2. Run Sonarqube in the terminal - `<PATH_TO_SONARQUBE>/bin` 
3. Log in and create a new local project
4. Choose to analyse the project "Locally", generate a token
5. Add the token, project name, and login details to the project's `.env` file
6. [Download](https://docs.sonarsource.com/sonarcloud/advanced-setup/ci-based-analysis/sonarscanner-cli/) and install SonarScanner locally
7. Set the SonarQube environment Variable - add these lines to the `~/.zshrc` file
   - `export SONAR_HOME=<PATH_TO_SONNARSCANNER>/{version}/libexec`
   - `export SONAR=$SONAR_HOME/bin export PATH=$SONAR:$PATH`

For Mac, it's possible to use [Homebrew](https://techblost.com/how-to-setup-sonarqube-locally-on-mac/) for easier installation process (steps 1-6 are sufficient)

### Build steps
The process of building the project encompasses a number of steps
1. Prepare the sample of repositories using the `src/get_samples.ipynb`
     - The sample used for our evaluation is stored in [data/evaluate_repositories.json](https://github.com/AlexChudic/FinalProject/blob/main/data/evaluate_repositories.json)
2. Run the pipeline by running the main method in [App.java](https://github.com/AlexChudic/FinalProject/blob/main/src/data-mining/mining/src/main/java/refactoring_mining/App.java)
     - The pipeline automatically analyses the repositories in the file [data/evaluate_repositories.json](https://github.com/AlexChudic/FinalProject/blob/main/data/evaluate_repositories.json)

### Test steps

There are no test cases which ensure the code has run correctly. 

If the pipeline runs correctly, JSON entries with refactoring data are stored in the `refactoring-data/` folder. The `src/evaluation.py` script will generate tables and figures with the evaluation metrics in the `data/` folder.
